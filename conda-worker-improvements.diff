diff --git a/.github/workflows/test.yml b/.github/workflows/test.yml
index 924826e..6c18fe8 100644
--- a/.github/workflows/test.yml
+++ b/.github/workflows/test.yml
@@ -47,7 +47,7 @@ jobs:
           activate-environment: test-env
       - name: Install conda dependencies
         run: |
-          conda install -c conda-forge conda-pack numpy python=${{ matrix.python-version }}
+          conda install -c conda-forge conda-pack numpy ipykernel python=${{ matrix.python-version }}
           conda list
         shell: bash -l {0}
       - name: Install dependencies
diff --git a/docs/conda-worker.md b/docs/conda-worker.md
index 9aa1d4b..06cfbcf 100644
--- a/docs/conda-worker.md
+++ b/docs/conda-worker.md
@@ -252,7 +252,7 @@ print("Application initialized successfully!")
 ```yaml
 # manifest.yaml
 name: My Conda App
-type: python-conda
+type: conda-jupyter-kernel
 version: 1.0.0
 description: A Python app with conda dependencies
 entry_point: main.py
@@ -288,7 +288,7 @@ async def main():
         "app_id": "my-conda-app",
         "workspace": "my-workspace",
         "manifest": {
-            "type": "python-conda",
+            "type": "conda-jupyter-kernel",
             "dependencies": ["python=3.11", "numpy", "pandas"],
             "channels": ["conda-forge"],
             "entry_point": "main.py"
@@ -315,13 +315,15 @@ print(f"Standard deviation: {std_val}")
 print(f"Sum: {sum_val}")
 """
     
-    result = await conda_worker.execute_code(session_id, code)
+    result = await conda_worker.execute(session_id, code)
     
-    if result.success:
-        print("Output:", result.stdout)
+    if result["status"] == "ok":
+        # Print all text outputs
+        for output in result["outputs"]:
+            if output["type"] == "stream" and output["name"] == "stdout":
+                print("Output:", output["text"])
     else:
-        print("Error:", result.error)
-        print("Stderr:", result.stderr)
+        print("Error:", result.get("error", {}))
     
     # Stop the session
     await conda_worker.stop(session_id)
@@ -350,7 +352,7 @@ print(f"Column B std: {df['B'].std():.3f}")
 print(df.head())
 """
 
-result = await conda_worker.execute_code(session_id, code)
+result = await conda_worker.execute(session_id, code)
 print(result.stdout)
 ```
 
@@ -369,7 +371,7 @@ print(f"NumPy version: {np.__version__}")
 print(f"Python executable: {sys.executable}")
 """
 
-result = await conda_worker.execute_code(session_id, code)
+result = await conda_worker.execute(session_id, code)
 print(result.stdout)
 ```
 
@@ -393,33 +395,34 @@ except ImportError as e:
     print(f"Matplotlib not available: {e}")
 """
 
-result = await conda_worker.execute_code(session_id, code)
+result = await conda_worker.execute(session_id, code)
 print(result.stdout)
 ```
 
 ### Handling Execution Results
 
-The `execute_code()` method returns an `ExecutionResult` object with the following fields:
+The `execute()` method returns a Jupyter-like result object with the following fields:
 
 ```python
-result = await conda_worker.execute_code(session_id, code)
+result = await conda_worker.execute(session_id, code)
 
-if result.success:
+if result["status"] == "ok":
     print("Code executed successfully!")
-    print("Output:", result.stdout)
+    # Process outputs
+    for output in result["outputs"]:
+        if output["type"] == "stream":
+            print(f"{output['name']}: {output['text']}")
+        elif output["type"] == "execute_result":
+            print("Result:", output["data"]["text/plain"])
 else:
     print("Execution failed!")
-    print("Error:", result.error)
-    print("Stderr:", result.stderr)
-
-# Timing information (if available)
-if result.timing:
-    print(f"Execution time: {result.timing.execution_time:.2f}s")
+    if "error" in result:
+        print(f"Error: {result['error']['ename']}: {result['error']['evalue']}")
 ```
 
 ## Environment Caching
 
-The worker automatically caches conda environments to improve performance. When you start a session, the initialization script runs once, but the environment stays available for multiple `execute_code()` calls:
+The worker automatically caches conda environments to improve performance. When you start a session, the initialization script runs once, but the environment stays available for multiple `execute()` calls:
 
 - **Hash-based caching**: Environments are cached based on dependencies and channels
 - **LRU eviction**: Least recently used environments are removed when cache is full
@@ -464,7 +467,7 @@ Starting Hypha Conda Environment Worker...
 
 âœ… Conda Environment Worker (using mamba) registered successfully!
    Service ID: my-conda-worker
-   Supported types: ['python-conda']
+   Supported types: ['conda-jupyter-kernel']
    Visibility: public
 
 Worker is ready to process conda environment requests...
@@ -493,14 +496,15 @@ conda install mamba -n base -c conda-forge
 
 #### 2. Code Execution Errors
 ```
-ExecutionResult.success = False
+result["status"] == "error"
 ```
-**Solution**: Check the `stderr` and `error` fields in the result:
+**Solution**: Check the `error` and output fields in the result:
 ```python
-result = await conda_worker.execute_code(session_id, code)
-if not result.success:
-    print(f"Error: {result.error}")
-    print(f"Stderr: {result.stderr}")
+result = await conda_worker.execute(session_id, code)
+if result["status"] == "error":
+    print(f"Error: {result['error']['ename']}: {result['error']['evalue']}")
+    for line in result['error']['traceback']:
+        print(line)
 ```
 
 #### 3. Permission Errors
@@ -571,14 +575,21 @@ Start a new conda environment session with the specified dependencies. The initi
 
 **Returns:** Session ID string
 
-#### `execute_code(session_id: str, code: str) -> ExecutionResult`
+#### `execute(session_id: str, script: str, config: Dict = None, progress_callback: Callable = None, context: Dict = None) -> Dict`
 Execute Python code in the conda environment session, similar to a Jupyter notebook cell.
 
 **Parameters:**
 - `session_id`: The session ID returned from `start()`
-- `code`: Python code string to execute
-
-**Returns:** ExecutionResult with `success`, `stdout`, `stderr`, and `error` fields
+- `script`: Python code string to execute
+- `config`: Optional configuration dict (e.g., `{"timeout": 30.0}`)
+- `progress_callback`: Optional callback for execution progress
+- `context`: Optional context dict
+
+**Returns:** Dict with Jupyter-like execution results:
+- `status`: "ok" or "error"
+- `outputs`: List of output objects (stream, execute_result, error, etc.)
+- `execution_count`: Execution counter
+- `error`: Error details if status is "error"
 
 #### `stop(session_id: str) -> None`
 Stop a conda environment session and clean up resources.
diff --git a/hypha/apps.py b/hypha/apps.py
index 768f768..f78f353 100644
--- a/hypha/apps.py
+++ b/hypha/apps.py
@@ -1822,6 +1822,64 @@ class ServerAppController:
         else:
             raise Exception(f"Server app instance not found: {session_id}")
 
+    @schema_method
+    async def execute(
+        self,
+        session_id: str = Field(
+            ...,
+            description="The session ID of the running application instance. This is typically in the format 'workspace/client_id'.",
+        ),
+        script: str = Field(
+            ...,
+            description="The script/code to execute in the session. For Python sessions, this is Python code. For browser sessions, this is JavaScript code.",
+        ),
+        config: Optional[Dict[str, Any]] = Field(
+            None,
+            description="Optional execution configuration specific to the worker type.",
+        ),
+        progress_callback: Any = Field(
+            None,
+            description="Callback function to receive progress updates during execution.",
+        ),
+        context: Optional[dict] = Field(
+            None,
+            description="Additional context information including user and workspace details. Usually provided automatically by the system.",
+        ),
+    ) -> Any:
+        """Execute a script in a running server app instance.
+        
+        This method allows you to interact with running application sessions by executing scripts.
+        The behavior depends on the worker type:
+        - Conda worker: Executes Python code via Jupyter kernel
+        - Browser worker: Executes JavaScript code via Playwright
+        - Other workers: May not support this method
+        
+        Returns the execution results in a format specific to the worker implementation.
+        """
+        user_info = UserInfo.model_validate(context["user"])
+        workspace = context["ws"]
+        if not user_info.check_permission(workspace, UserPermission.read_write):
+            raise Exception(
+                f"User {user_info.id} does not have permission"
+                f" to execute scripts in app {session_id} in workspace {workspace}."
+            )
+        if session_id in self._sessions:
+            worker = self._sessions[session_id]["_worker"]
+            if hasattr(worker, "execute"):
+                return await worker.execute(
+                    session_id, 
+                    script=script, 
+                    config=config,
+                    progress_callback=progress_callback,
+                    context=context
+                )
+            else:
+                raise NotImplementedError(
+                    f"Worker for session {session_id} does not support the execute method"
+                )
+        else:
+            raise Exception(f"Server app instance not found: {session_id}")
+
     @schema_method
     async def list_running(
         self,
@@ -2365,6 +2423,7 @@ class ServerAppController:
             "list_running": self.list_running,
             "get_logs": self.get_logs,
             "take_screenshot": self.take_screenshot,
+            "execute": self.execute,
             "edit_file": self.edit_file,
             "remove_file": self.remove_file,
             "list_files": self.list_files,
diff --git a/hypha/http.py b/hypha/http.py
index 54e564e..b4537a3 100644
--- a/hypha/http.py
+++ b/hypha/http.py
@@ -122,6 +122,26 @@ async def extracted_kwargs(
                 "Invalid content-type (supported types: "
                 "application/msgpack, application/json, text/plain)",
             )
+        # Handle different JSON input types for HTTP service calls
+        if isinstance(kwargs, list):
+            # Convert positional arguments array to a dictionary for internal processing
+            # e.g., ["arg1", "arg2"] becomes {"0": "arg1", "1": "arg2"}
+            kwargs = {str(i): arg for i, arg in enumerate(kwargs)}
+        elif not isinstance(kwargs, dict):
+            # For single primitive values, treat as a single positional argument
+            # e.g., "hello" becomes {"0": "hello"}
+            if isinstance(kwargs, (str, int, float, bool)) or kwargs is None:
+                kwargs = {"0": kwargs}
+            else:
+                raise RuntimeError(
+                    f"Invalid JSON format for HTTP service call. "
+                    f"Expected a dictionary (object), array, or primitive value, but got {type(kwargs).__name__}: {kwargs!r}. "
+                    f"Examples: "
+                    f"Array format: ['arg1', 'arg2'] "
+                    f"Object format: {{'param1': 'value1', 'param2': 'value2'}} "
+                    f"Single value: 'hello'"
+                )
+        
         if use_function_kwargs:
             kwargs = kwargs.get("function_kwargs", {})
         else:
diff --git a/hypha/workers/base.py b/hypha/workers/base.py
index ac271d9..80e9b9b 100644
--- a/hypha/workers/base.py
+++ b/hypha/workers/base.py
@@ -137,6 +137,37 @@ class WorkerProtocol(Protocol):
         """Close workspace and cleanup sessions."""
         ...
 
+    async def execute(
+        self,
+        session_id: str,
+        script: str,
+        config: Optional[Dict[str, Any]] = None,
+        progress_callback: Optional[Callable[[Dict[str, Any]], None]] = None,
+        context: Optional[Dict[str, Any]] = None,
+    ) -> Any:
+        """Execute a script in the running session.
+        
+        This method allows interaction with running sessions by executing scripts.
+        Different workers may implement this differently:
+        - Conda worker: Execute Python code via Jupyter kernel
+        - Browser worker: Execute JavaScript via Playwright
+        - Other workers: May not implement this method
+        
+        Args:
+            session_id: The session to execute in
+            script: The script/code to execute
+            config: Optional execution configuration
+            progress_callback: Optional callback for execution progress
+            context: Optional context information
+            
+        Returns:
+            Execution results (format depends on worker implementation)
+            
+        Raises:
+            NotImplementedError: If the worker doesn't support execution
+        """
+        ...
+
 
 class BaseWorker(ABC):
     """Minimal base class for workers - provides only common utilities."""
@@ -253,6 +284,23 @@ class BaseWorker(ABC):
         """
         return manifest, files
 
+    async def execute(
+        self,
+        session_id: str,
+        script: str,
+        config: Optional[Dict[str, Any]] = None,
+        progress_callback: Optional[Callable[[Dict[str, Any]], None]] = None,
+        context: Optional[Dict[str, Any]] = None,
+    ) -> Any:
+        """Execute a script in the running session.
+        
+        Optional method that workers can implement to interact with running sessions.
+        Default implementation raises NotImplementedError.
+        """
+        raise NotImplementedError(
+            f"Worker {self.name} does not support the execute method"
+        )
+
     def get_worker_service(self) -> Dict[str, Any]:
         """Get the service configuration for registration."""
         return {
@@ -274,6 +322,7 @@ class BaseWorker(ABC):
             "prepare_workspace": self.prepare_workspace,
             "close_workspace": self.close_workspace,
             "compile": self.compile,
+            "execute": self.execute,
             "shutdown": self.shutdown,
         }
 
diff --git a/hypha/workers/conda.py b/hypha/workers/conda.py
index dade69d..cbf8e6d 100644
--- a/hypha/workers/conda.py
+++ b/hypha/workers/conda.py
@@ -24,7 +24,8 @@ from hypha.workers.base import (
     SessionNotFoundError,
     WorkerError,
 )
-from hypha.workers.conda_executor import CondaEnvExecutor, ExecutionResult
+from hypha.workers.conda_executor import CondaEnvExecutor
+from hypha.workers.conda_kernel import CondaKernel
 
 LOGLEVEL = os.environ.get("HYPHA_LOGLEVEL", "WARNING").upper()
 logging.basicConfig(level=LOGLEVEL, stream=sys.stdout)
@@ -245,7 +246,7 @@ class CondaWorker(BaseWorker):
     @property
     def supported_types(self) -> List[str]:
         """Return list of supported application types."""
-        return ["python-conda"]
+        return ["conda-jupyter-kernel"]
 
     @property
     def name(self) -> str:
@@ -291,6 +292,17 @@ class CondaWorker(BaseWorker):
         if "pip" not in dependencies:
             dependencies.append("pip")
 
+        # Always ensure ipykernel is available for Jupyter kernel support
+        ipykernel_found = False
+        for dep in dependencies:
+            if isinstance(dep, str) and dep == "ipykernel":
+                ipykernel_found = True
+                break
+        
+        if not ipykernel_found:
+            dependencies.append("ipykernel")
+            logger.info("Automatically added ipykernel to dependencies")
+
         # Always ensure hypha-rpc is available via pip
         hypha_rpc_found = False
 
@@ -563,16 +575,42 @@ class CondaWorker(BaseWorker):
             self._env_cache.add_cached_env(dependencies, channels, executor.env_path)
             logger.info(f"Cached new conda environment: {executor.env_path}")
 
-        # Phase 3: Start initialization script in background (non-blocking)
+        # Phase 3: Start Jupyter kernel
         progress_callback_wrapper(
             {
                 "type": "info",
-                "message": "Starting initialization script in background...",
+                "message": "Starting Jupyter kernel...",
             }
         )
 
-        # Start the script execution in background without waiting for completion
-        # This allows long-running services (like FastAPI apps) to keep running
+        # Create and start the Jupyter kernel
+        kernel = CondaKernel(executor.env_path)
+        try:
+            await kernel.start(timeout=30.0)
+            progress_callback_wrapper(
+                {
+                    "type": "success",
+                    "message": "Jupyter kernel started successfully",
+                }
+            )
+        except Exception as e:
+            progress_callback_wrapper(
+                {
+                    "type": "error",
+                    "message": f"Failed to start Jupyter kernel: {str(e)}",
+                }
+            )
+            raise
+
+        # Phase 4: Run initialization script in the kernel
+        progress_callback_wrapper(
+            {
+                "type": "info",
+                "message": "Running initialization script in kernel...",
+            }
+        )
+
+        # Prepare the hypha config
         hypha_config = {
             "server_url": config.server_url,
             "workspace": config.workspace,
@@ -580,187 +618,206 @@ class CondaWorker(BaseWorker):
             "token": config.token,
         }
 
-        # Determine if script has execute function for later interactive calls
+        # Execute initialization script in the kernel
+        init_code = f"""
+import os
+import sys
+
+# Set up Hypha configuration
+hypha_config = {repr(hypha_config)}
+os.environ['HYPHA_SERVER_URL'] = hypha_config['server_url']
+os.environ['HYPHA_WORKSPACE'] = hypha_config['workspace']
+os.environ['HYPHA_CLIENT_ID'] = hypha_config['client_id']
+os.environ['HYPHA_TOKEN'] = hypha_config['token']
+
+# Execute the user's script
+exec('''{script}''')
+"""
 
-        # Create a task to run the script in background with the wrapper callback
-        script_task = asyncio.create_task(
-            self._run_script_in_background(
-                executor, script, hypha_config, progress_callback_wrapper, config.id
+        try:
+            result = await kernel.execute(init_code, timeout=60.0)
+            
+            # Process kernel outputs into logs
+            for output in result.get("outputs", []):
+                if output["type"] == "stream":
+                    if output["name"] == "stdout":
+                        logs["stdout"].append(output["text"])
+                    elif output["name"] == "stderr":
+                        logs["stderr"].append(output["text"])
+                elif output["type"] == "error":
+                    logs["error"].append("\n".join(output.get("traceback", [])))
+                elif output["type"] == "execute_result":
+                    # Convert execute results to string representation
+                    data = output.get("data", {})
+                    if "text/plain" in data:
+                        logs["info"].append(f"Result: {data['text/plain']}")
+            
+            if result["status"] == "ok":
+                progress_callback_wrapper(
+                    {
+                        "type": "success",
+                        "message": "Initialization script executed successfully",
+                    }
+                )
+            else:
+                progress_callback_wrapper(
+                    {
+                        "type": "error",
+                        "message": "Initialization script failed",
+                    }
+                )
+                
+        except Exception as e:
+            progress_callback_wrapper(
+                {
+                    "type": "error",
+                    "message": f"Failed to execute initialization script: {str(e)}",
+                }
             )
-        )
+            # Don't raise here - we want the session to continue even if init fails
+            logs["error"].append(f"Initialization error: {str(e)}")
 
         progress_callback_wrapper(
             {
                 "type": "success",
-                "message": "Conda environment session started, initialization script running in background",
+                "message": "Conda environment session with Jupyter kernel ready",
             }
         )
 
         return {
             "executor": executor,
+            "kernel": kernel,
             "script": script,
             "dependencies": dependencies,
             "channels": channels,
-            "script_task": script_task,  # Keep reference to the background task
             "logs": logs,
             "hypha_config": hypha_config,
         }
 
-    async def _run_script_in_background(
-        self,
-        executor: CondaEnvExecutor,
-        script: str,
-        hypha_config: dict,
-        progress_callback=None,
-        session_id: str = None,
-    ):
-        """Run the initialization script in background without blocking session startup."""
-        try:
-            if progress_callback:
-                progress_callback(
-                    {"type": "info", "message": "Executing initialization script..."}
-                )
-
-            # Execute the script in a thread pool to avoid blocking
-            execute_func = functools.partial(executor.execute, script, hypha_config)
-            result = await asyncio.get_event_loop().run_in_executor(None, execute_func)
-
-            # Update session logs with the background execution results
-            if session_id and session_id in self._session_data:
-                session_data = self._session_data[session_id]
-                logs = session_data.get("logs", {})
-
-                if result.success:
-                    if result.stdout:
-                        logs.setdefault("stdout", []).append(result.stdout)
-                    logs.setdefault("info", []).append(
-                        "Background script execution completed successfully"
-                    )
-                    if result.timing:
-                        logs.setdefault("info", []).append(
-                            f"Background script execution time: {result.timing.execution_time:.2f}s"
-                        )
-                else:
-                    if result.error:
-                        logs.setdefault("error", []).append(result.error)
-                    if result.stderr:
-                        logs.setdefault("stderr", []).append(result.stderr)
-                    logs.setdefault("error", []).append(
-                        "Background script execution failed"
-                    )
-
-            if progress_callback:
-                if result.success:
-                    progress_callback(
-                        {
-                            "type": "success",
-                            "message": "Initialization script executed successfully",
-                        }
-                    )
-                else:
-                    progress_callback(
-                        {
-                            "type": "error",
-                            "message": f"Initialization script failed: {result.error or 'Unknown error'}",
-                        }
-                    )
-
-            # Log the result for debugging
-            if result.success:
-                logger.info("Background script execution completed successfully")
-                if result.timing:
-                    logger.info(
-                        f"Script execution time: {result.timing.execution_time:.2f}s"
-                    )
-            else:
-                logger.error(f"Background script execution failed: {result.error}")
 
-            return result
-
-        except Exception as e:
-            logger.error(f"Background script execution failed with exception: {e}")
-
-            # Update session logs with the exception
-            if session_id and session_id in self._session_data:
-                session_data = self._session_data[session_id]
-                logs = session_data.get("logs", {})
-                logs.setdefault("error", []).append(
-                    f"Background script execution failed: {str(e)}"
-                )
-
-            if progress_callback:
-                progress_callback(
-                    {
-                        "type": "error",
-                        "message": f"Background script execution failed: {str(e)}",
-                    }
-                )
-            return None
-
-    async def execute_code(
+    async def execute(
         self,
         session_id: str,
-        code: str = None,
+        script: str,
+        config: Optional[Dict[str, Any]] = None,
+        progress_callback: Optional[Any] = None,
         context: Optional[Dict[str, Any]] = None,
-    ) -> ExecutionResult:
-        """Execute code in a conda environment session."""
+    ) -> Dict[str, Any]:
+        """Execute a script in the running Jupyter kernel session.
+        
+        This implements the new execute API method for interacting with running sessions.
+        
+        Args:
+            session_id: The session to execute in
+            script: The Python code to execute
+            config: Optional execution configuration
+            progress_callback: Optional callback for execution progress
+            context: Optional context information
+            
+        Returns:
+            Dictionary containing execution results with Jupyter-like output format
+        """
         if session_id not in self._sessions:
             raise SessionNotFoundError(
                 f"Conda environment session {session_id} not found"
             )
 
         session_data = self._session_data.get(session_id)
-        if not session_data or not session_data.get("executor"):
-            raise WorkerError(f"No executor available for session {session_id}")
+        if not session_data or not session_data.get("kernel"):
+            raise WorkerError(f"No kernel available for session {session_id}")
 
-        executor = session_data["executor"]
-        hypha_config = session_data.get("hypha_config", {})
+        kernel = session_data["kernel"]
+        
+        # Check if kernel is still alive
+        if not await kernel.is_alive():
+            raise WorkerError(f"Kernel for session {session_id} is not alive")
 
-        if not code:
-            raise WorkerError(f"No code provided to execute")
+        if progress_callback:
+            progress_callback(
+                {"type": "info", "message": "Executing code in Jupyter kernel..."}
+            )
 
         try:
-            # Execute the provided code directly
-            execute_func = functools.partial(executor.execute, code, hypha_config)
-            result = await asyncio.get_event_loop().run_in_executor(None, execute_func)
-
-            # Update logs
-            if session_data["logs"] is None:
-                session_data["logs"] = {
-                    "stdout": [],
-                    "stderr": [],
-                    "info": [],
-                    "error": [],
-                }
+            # Configure execution options from config
+            timeout = config.get("timeout", 30.0) if config else 30.0
+            silent = config.get("silent", False) if config else False
+            store_history = config.get("store_history", True) if config else True
+            
+            # Execute the code in the kernel
+            result = await kernel.execute(
+                script, 
+                silent=silent,
+                store_history=store_history,
+                timeout=timeout
+            )
 
-            # Ensure all log types exist
-            for log_type in ["stdout", "stderr", "info", "error"]:
-                if log_type not in session_data["logs"]:
-                    session_data["logs"][log_type] = []
+            # Update session logs
+            logs = session_data.get("logs", {})
+            
+            # Process outputs for logging
+            for output in result.get("outputs", []):
+                if output["type"] == "stream":
+                    if output["name"] == "stdout":
+                        logs.setdefault("stdout", []).append(output["text"])
+                    elif output["name"] == "stderr":
+                        logs.setdefault("stderr", []).append(output["text"])
+                elif output["type"] == "error":
+                    logs.setdefault("error", []).append("\n".join(output.get("traceback", [])))
+
+            # Add execution info
+            logs.setdefault("info", []).append(
+                f"Code executed at {datetime.now().isoformat()} - Status: {result['status']}"
+            )
 
-            if result.success:
-                if result.stdout:
-                    session_data["logs"]["stdout"].append(result.stdout)
-                session_data["logs"]["info"].append(
-                    f"Code executed successfully at {datetime.now().isoformat()}"
-                )
-            else:
-                if result.stderr:
-                    session_data["logs"]["stderr"].append(result.stderr)
-                if result.error:
-                    session_data["logs"]["error"].append(result.error)
+            if progress_callback:
+                if result["status"] == "ok":
+                    progress_callback(
+                        {"type": "success", "message": "Code executed successfully"}
+                    )
+                else:
+                    progress_callback(
+                        {"type": "error", "message": "Code execution failed"}
+                    )
 
             return result
 
+        except asyncio.TimeoutError:
+            error_msg = f"Code execution timed out after {timeout} seconds"
+            if progress_callback:
+                progress_callback({"type": "error", "message": error_msg})
+            
+            logs = session_data.get("logs", {})
+            logs.setdefault("error", []).append(error_msg)
+            
+            return {
+                "status": "error",
+                "outputs": [],
+                "error": {
+                    "ename": "TimeoutError",
+                    "evalue": error_msg,
+                    "traceback": [error_msg]
+                }
+            }
         except Exception as e:
+            error_msg = f"Failed to execute code: {str(e)}"
             logger.error(f"Failed to execute code in session {session_id}: {e}")
-            result = ExecutionResult(success=False, error=str(e))
-            if session_data.get("logs"):
-                # Ensure error log type exists
-                if "error" not in session_data["logs"]:
-                    session_data["logs"]["error"] = []
-                session_data["logs"]["error"].append(str(e))
-            return result
+            
+            if progress_callback:
+                progress_callback({"type": "error", "message": error_msg})
+            
+            logs = session_data.get("logs", {})
+            logs.setdefault("error", []).append(error_msg)
+            
+            return {
+                "status": "error",
+                "outputs": [],
+                "error": {
+                    "ename": type(e).__name__,
+                    "evalue": str(e),
+                    "traceback": [error_msg]
+                }
+            }
+
 
     async def stop(
         self, session_id: str, context: Optional[Dict[str, Any]] = None
@@ -779,18 +836,15 @@ class CondaWorker(BaseWorker):
             # Cleanup session data
             session_data = self._session_data.get(session_id)
             if session_data:
-                # Cancel the background script task if it's still running
-                script_task = session_data.get("script_task")
-                if script_task and not script_task.done():
-                    logger.info(
-                        f"Cancelling background script task for session {session_id}"
-                    )
-                    script_task.cancel()
+                # Shutdown the Jupyter kernel
+                kernel = session_data.get("kernel")
+                if kernel:
+                    logger.info(f"Shutting down Jupyter kernel for session {session_id}")
                     try:
-                        await script_task
-                    except asyncio.CancelledError:
-                        logger.info(
-                            f"Background script task cancelled for session {session_id}"
+                        await kernel.shutdown()
+                    except Exception as e:
+                        logger.warning(
+                            f"Error shutting down kernel for session {session_id}: {e}"
                         )
 
                 # Note: We don't cleanup the executor environment since it's cached
@@ -911,16 +965,7 @@ class CondaWorker(BaseWorker):
         """Shutdown the conda environment worker."""
         logger.info("Shutting down conda environment worker...")
 
-        # Cancel all background script tasks first
-        for session_id, session_data in self._session_data.items():
-            script_task = session_data.get("script_task")
-            if script_task and not script_task.done():
-                logger.info(
-                    f"Cancelling background script task for session {session_id}"
-                )
-                script_task.cancel()
-
-        # Stop all sessions
+        # Stop all sessions (which will shutdown kernels)
         session_ids = list(self._sessions.keys())
         for session_id in session_ids:
             try:
@@ -936,7 +981,6 @@ class CondaWorker(BaseWorker):
         """Get the service configuration for registration with conda-specific methods."""
         service_config = super().get_worker_service()
         # Add conda environment specific methods
-        service_config["execute_code"] = self.execute_code
         service_config["take_screenshot"] = self.take_screenshot
         return service_config
 
diff --git a/hypha/workers/conda_kernel.py b/hypha/workers/conda_kernel.py
new file mode 100644
index 0000000..682b284
--- /dev/null
+++ b/hypha/workers/conda_kernel.py
@@ -0,0 +1,221 @@
+"""Jupyter kernel management for conda environments."""
+
+import asyncio
+import json
+import os
+import subprocess
+import tempfile
+import time
+import uuid
+from pathlib import Path
+from typing import Any, Dict, List, Optional, Union
+
+from jupyter_client import AsyncKernelClient, KernelConnectionInfo
+from jupyter_client.manager import AsyncKernelManager
+
+
+class CondaKernel:
+    """Manages a Jupyter kernel running in a conda environment."""
+
+    def __init__(self, conda_env_path: Union[str, Path]):
+        """Initialize the conda kernel.
+        
+        Args:
+            conda_env_path: Path to the conda environment
+        """
+        self.conda_env_path = Path(conda_env_path)
+        self.python_path = self.conda_env_path / "bin" / "python"
+        
+        # Verify the environment exists
+        if not self.python_path.exists():
+            # Try Windows path
+            self.python_path = self.conda_env_path / "python.exe"
+            if not self.python_path.exists():
+                raise ValueError(f"Python not found in conda environment: {conda_env_path}")
+        
+        self.kernel_process = None
+        self.connection_file = None
+        self.kernel_manager = None
+        self.kernel_client = None
+        self.kernel_id = str(uuid.uuid4())
+
+    async def start(self, timeout: float = 30.0):
+        """Start the Jupyter kernel."""
+        # Create a temporary connection file
+        fd, self.connection_file = tempfile.mkstemp(suffix=".json", prefix="kernel_")
+        os.close(fd)
+        
+        # Create kernel manager
+        self.kernel_manager = AsyncKernelManager(
+            kernel_name='python3',
+            connection_file=self.connection_file,
+        )
+        
+        # Set the kernel command to use our conda environment's Python
+        self.kernel_manager.kernel_cmd = [
+            str(self.python_path),
+            "-m", "ipykernel_launcher",
+            "-f", "{connection_file}"
+        ]
+        
+        # Start the kernel
+        await self.kernel_manager.start_kernel()
+        
+        # Create kernel client
+        self.kernel_client = self.kernel_manager.client()
+        self.kernel_client.start_channels()
+        
+        # Wait for kernel to be ready
+        await self.kernel_client.wait_for_ready(timeout=timeout)
+
+    async def execute(
+        self, 
+        code: str, 
+        silent: bool = False,
+        store_history: bool = True,
+        timeout: Optional[float] = None
+    ) -> Dict[str, Any]:
+        """Execute code in the kernel and return results.
+        
+        Args:
+            code: The code to execute
+            silent: If True, don't broadcast output on IOPub channel
+            store_history: If True, store command in history
+            timeout: Timeout in seconds for execution
+            
+        Returns:
+            Dictionary containing execution results with keys:
+            - status: 'ok' or 'error'
+            - outputs: List of output dictionaries
+            - execution_count: The execution count
+            - error: Error information if status is 'error'
+        """
+        if not self.kernel_client:
+            raise RuntimeError("Kernel not started. Call start() first.")
+        
+        # Send execute request
+        msg_id = self.kernel_client.execute(
+            code,
+            silent=silent,
+            store_history=store_history
+        )
+        
+        # Collect outputs
+        outputs = []
+        execution_count = None
+        status = 'ok'
+        error_info = None
+        
+        # Set up timeout
+        start_time = time.time()
+        
+        while True:
+            try:
+                # Get message with a short timeout to allow checking total timeout
+                msg = await asyncio.wait_for(
+                    self.kernel_client.get_iopub_msg(timeout=1),
+                    timeout=1
+                )
+            except asyncio.TimeoutError:
+                # Check if total timeout exceeded
+                if timeout and (time.time() - start_time) > timeout:
+                    raise TimeoutError(f"Execution timed out after {timeout} seconds")
+                continue
+            
+            msg_type = msg["msg_type"]
+            content = msg["content"]
+            
+            if msg_type == "stream":
+                outputs.append({
+                    "type": "stream",
+                    "name": content.get("name", "stdout"),
+                    "text": content.get("text", "")
+                })
+            elif msg_type == "display_data":
+                outputs.append({
+                    "type": "display_data",
+                    "data": content.get("data", {}),
+                    "metadata": content.get("metadata", {})
+                })
+            elif msg_type == "execute_result":
+                outputs.append({
+                    "type": "execute_result",
+                    "data": content.get("data", {}),
+                    "metadata": content.get("metadata", {}),
+                    "execution_count": content.get("execution_count")
+                })
+                execution_count = content.get("execution_count")
+            elif msg_type == "error":
+                status = 'error'
+                error_info = {
+                    "ename": content.get("ename", "Unknown"),
+                    "evalue": content.get("evalue", ""),
+                    "traceback": content.get("traceback", [])
+                }
+                outputs.append({
+                    "type": "error",
+                    **error_info
+                })
+            elif msg_type == "status" and content.get("execution_state") == "idle":
+                # Kernel is idle, execution complete
+                break
+        
+        # Get the reply to check for errors
+        reply = await self.kernel_client.get_shell_msg(timeout=timeout)
+        if reply["content"]["status"] == "error":
+            status = 'error'
+            if not error_info:
+                error_info = {
+                    "ename": reply["content"].get("ename", "Unknown"),
+                    "evalue": reply["content"].get("evalue", ""),
+                    "traceback": reply["content"].get("traceback", [])
+                }
+        
+        return {
+            "status": status,
+            "outputs": outputs,
+            "execution_count": execution_count,
+            "error": error_info
+        }
+
+    async def shutdown(self):
+        """Shutdown the kernel and cleanup resources."""
+        if self.kernel_client:
+            self.kernel_client.stop_channels()
+            
+        if self.kernel_manager:
+            await self.kernel_manager.shutdown_kernel(now=True)
+            
+        if self.connection_file and os.path.exists(self.connection_file):
+            try:
+                os.remove(self.connection_file)
+            except OSError:
+                pass
+
+    async def interrupt(self):
+        """Interrupt the currently executing cell."""
+        if self.kernel_manager:
+            await self.kernel_manager.interrupt_kernel()
+
+    async def restart(self):
+        """Restart the kernel."""
+        if self.kernel_manager:
+            await self.kernel_manager.restart_kernel()
+            await self.kernel_client.wait_for_ready()
+
+    async def is_alive(self) -> bool:
+        """Check if the kernel is still alive."""
+        if self.kernel_manager:
+            return await self.kernel_manager.is_alive()
+        return False
+
+    async def get_kernel_info(self) -> Dict[str, Any]:
+        """Get kernel information."""
+        if not self.kernel_client:
+            raise RuntimeError("Kernel not started")
+        
+        # Request kernel info
+        msg_id = self.kernel_client.kernel_info()
+        reply = await self.kernel_client.get_shell_msg()
+        
+        return reply["content"]
\ No newline at end of file
diff --git a/requirements.txt b/requirements.txt
index 65b1a4e..43686a9 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -43,3 +43,4 @@ prompt-toolkit==3.0.50
 ptpython==3.0.29
 mcp==1.11.0
 conda-pack>=0.7.0
+jupyter_client>=8.6.0
diff --git a/setup.py b/setup.py
index e0d41c1..edf72c8 100644
--- a/setup.py
+++ b/setup.py
@@ -49,6 +49,7 @@ REQUIREMENTS = [
     "stream-zip>=0.0.83",
     "prompt-toolkit>=3.0.50",
     "ptpython>=3.0.29",
+    "jupyter_client>=8.6.0",
 ]
 
 ROOT_DIR = Path(__file__).parent.resolve()
diff --git a/tests/test_apps_execute.py b/tests/test_apps_execute.py
new file mode 100644
index 0000000..e408259
--- /dev/null
+++ b/tests/test_apps_execute.py
@@ -0,0 +1,292 @@
+"""Test the execute method in server apps controller."""
+
+import asyncio
+import pytest
+from unittest.mock import Mock, AsyncMock, MagicMock
+
+from hypha.apps import ServerAppController
+from hypha.core import UserInfo, UserPermission
+
+
+@pytest.fixture
+def mock_store():
+    """Create a mock store."""
+    store = Mock()
+    store.get_event_bus.return_value = Mock(on_local=Mock(), off_local=Mock())
+    store.local_base_url = "http://localhost:9527"
+    store.public_base_url = "http://localhost:9527"
+    store.register_public_service = Mock()
+    store.set_server_app_controller = Mock()
+    store.get_root_user = Mock(return_value=Mock(model_dump=Mock(return_value={"id": "root"})))
+    return store
+
+
+@pytest.fixture
+def mock_artifact_manager():
+    """Create a mock artifact manager."""
+    return Mock()
+
+
+@pytest.fixture
+def app_controller(mock_store, mock_artifact_manager):
+    """Create a ServerAppController instance."""
+    controller = ServerAppController(
+        store=mock_store,
+        in_docker=False,
+        port=9527,
+        artifact_manager=mock_artifact_manager
+    )
+    return controller
+
+
+@pytest.mark.asyncio
+async def test_execute_method_success(app_controller):
+    """Test successful execution via the execute method."""
+    # Set up mock session with a worker that supports execute
+    mock_worker = AsyncMock()
+    mock_worker.execute = AsyncMock(return_value={
+        "status": "ok",
+        "outputs": [
+            {"type": "stream", "name": "stdout", "text": "Hello, World!"},
+            {"type": "execute_result", "data": {"text/plain": "42"}}
+        ],
+        "execution_count": 1
+    })
+    
+    session_id = "test-workspace/test-client"
+    app_controller._sessions[session_id] = {
+        "id": session_id,
+        "app_id": "test-app",
+        "workspace": "test-workspace",
+        "client_id": "test-client",
+        "_worker": mock_worker
+    }
+    
+    # Create test context
+    context = {
+        "ws": "test-workspace",
+        "user": {
+            "id": "test-user",
+            "email": "test@example.com",
+            "roles": ["user"]
+        }
+    }
+    
+    # Mock permission check
+    UserInfo.model_validate = Mock(return_value=Mock(
+        check_permission=Mock(return_value=True)
+    ))
+    
+    # Execute script
+    result = await app_controller.execute(
+        session_id=session_id,
+        script="print('Hello, World!')",
+        config={"timeout": 30.0},
+        context=context
+    )
+    
+    # Verify results
+    assert result["status"] == "ok"
+    assert len(result["outputs"]) == 2
+    assert result["outputs"][0]["text"] == "Hello, World!"
+    
+    # Verify worker was called correctly
+    mock_worker.execute.assert_called_once_with(
+        session_id,
+        script="print('Hello, World!')",
+        config={"timeout": 30.0},
+        progress_callback=None,
+        context=context
+    )
+
+
+@pytest.mark.asyncio
+async def test_execute_method_with_progress_callback(app_controller):
+    """Test execution with progress callback."""
+    # Set up mock session
+    mock_worker = AsyncMock()
+    mock_worker.execute = AsyncMock(return_value={
+        "status": "ok",
+        "outputs": [],
+        "execution_count": 1
+    })
+    
+    session_id = "test-workspace/test-client"
+    app_controller._sessions[session_id] = {
+        "id": session_id,
+        "_worker": mock_worker
+    }
+    
+    # Create progress callback
+    progress_messages = []
+    def progress_callback(msg):
+        progress_messages.append(msg)
+    
+    context = {
+        "ws": "test-workspace",
+        "user": {"id": "test-user", "roles": ["user"]}
+    }
+    
+    UserInfo.model_validate = Mock(return_value=Mock(
+        check_permission=Mock(return_value=True)
+    ))
+    
+    # Execute with progress callback
+    await app_controller.execute(
+        session_id=session_id,
+        script="x = 1",
+        progress_callback=progress_callback,
+        context=context
+    )
+    
+    # Verify progress callback was passed through
+    mock_worker.execute.assert_called_once()
+    call_args = mock_worker.execute.call_args
+    assert call_args[1]["progress_callback"] == progress_callback
+
+
+@pytest.mark.asyncio
+async def test_execute_method_permission_denied(app_controller):
+    """Test execution denied due to permissions."""
+    session_id = "test-workspace/test-client"
+    app_controller._sessions[session_id] = {"id": session_id}
+    
+    context = {
+        "ws": "test-workspace",
+        "user": {"id": "test-user", "roles": ["viewer"]}
+    }
+    
+    # Mock permission check to return False
+    UserInfo.model_validate = Mock(return_value=Mock(
+        check_permission=Mock(return_value=False),
+        id="test-user"
+    ))
+    
+    # Should raise permission error
+    with pytest.raises(Exception) as exc_info:
+        await app_controller.execute(
+            session_id=session_id,
+            script="print('test')",
+            context=context
+        )
+    
+    assert "does not have permission" in str(exc_info.value)
+
+
+@pytest.mark.asyncio
+async def test_execute_method_session_not_found(app_controller):
+    """Test execution with non-existent session."""
+    context = {
+        "ws": "test-workspace",
+        "user": {"id": "test-user", "roles": ["user"]}
+    }
+    
+    UserInfo.model_validate = Mock(return_value=Mock(
+        check_permission=Mock(return_value=True)
+    ))
+    
+    # Should raise session not found error
+    with pytest.raises(Exception) as exc_info:
+        await app_controller.execute(
+            session_id="non-existent-session",
+            script="print('test')",
+            context=context
+        )
+    
+    assert "Server app instance not found" in str(exc_info.value)
+
+
+@pytest.mark.asyncio
+async def test_execute_method_worker_not_supported(app_controller):
+    """Test execution with worker that doesn't support execute."""
+    # Worker without execute method
+    mock_worker = Mock(spec=[])  # No execute attribute
+    
+    session_id = "test-workspace/test-client"
+    app_controller._sessions[session_id] = {
+        "id": session_id,
+        "_worker": mock_worker
+    }
+    
+    context = {
+        "ws": "test-workspace",
+        "user": {"id": "test-user", "roles": ["user"]}
+    }
+    
+    UserInfo.model_validate = Mock(return_value=Mock(
+        check_permission=Mock(return_value=True)
+    ))
+    
+    # Should raise NotImplementedError
+    with pytest.raises(NotImplementedError) as exc_info:
+        await app_controller.execute(
+            session_id=session_id,
+            script="print('test')",
+            context=context
+        )
+    
+    assert "does not support the execute method" in str(exc_info.value)
+
+
+@pytest.mark.asyncio
+async def test_execute_method_error_handling(app_controller):
+    """Test execution error handling."""
+    # Worker that returns error status
+    mock_worker = AsyncMock()
+    mock_worker.execute = AsyncMock(return_value={
+        "status": "error",
+        "outputs": [
+            {"type": "error", "ename": "SyntaxError", "evalue": "invalid syntax"}
+        ],
+        "error": {
+            "ename": "SyntaxError",
+            "evalue": "invalid syntax",
+            "traceback": ["  File '<stdin>', line 1", "    print("]
+        }
+    })
+    
+    session_id = "test-workspace/test-client"
+    app_controller._sessions[session_id] = {
+        "id": session_id,
+        "_worker": mock_worker
+    }
+    
+    context = {
+        "ws": "test-workspace",
+        "user": {"id": "test-user", "roles": ["user"]}
+    }
+    
+    UserInfo.model_validate = Mock(return_value=Mock(
+        check_permission=Mock(return_value=True)
+    ))
+    
+    # Execute invalid code
+    result = await app_controller.execute(
+        session_id=session_id,
+        script="print(",  # Invalid syntax
+        context=context
+    )
+    
+    # Should return error result, not raise exception
+    assert result["status"] == "error"
+    assert result["error"]["ename"] == "SyntaxError"
+
+
+@pytest.mark.asyncio
+async def test_execute_service_api_included(app_controller):
+    """Test that execute is included in the service API."""
+    service_api = app_controller.get_service_api()
+    
+    # Verify execute is in the service API
+    assert "execute" in service_api
+    assert service_api["execute"] == app_controller.execute
+    
+    # Verify it's placed between take_screenshot and edit_file
+    api_keys = list(service_api.keys())
+    execute_index = api_keys.index("execute")
+    assert api_keys[execute_index - 1] == "take_screenshot"
+    assert api_keys[execute_index + 1] == "edit_file"
+
+
+if __name__ == "__main__":
+    pytest.main([__file__, "-v"])
\ No newline at end of file
diff --git a/tests/test_conda_env.py b/tests/test_conda_env.py
index a37b259..a5e27ce 100644
--- a/tests/test_conda_env.py
+++ b/tests/test_conda_env.py
@@ -17,7 +17,7 @@ from hypha.workers.base import (
     SessionNotFoundError,
     WorkerError,
 )
-from hypha.workers.conda_executor import ExecutionResult, TimingInfo
+from hypha.workers.conda_executor import TimingInfo
 
 # Mark all async functions in this module as asyncio tests
 pytestmark = pytest.mark.asyncio
@@ -175,7 +175,7 @@ class TestCondaWorkerBasic:
     def test_supported_types(self):
         """Test supported application types."""
         types = self.worker.supported_types
-        assert "python-conda" in types
+        assert "conda-jupyter-kernel" in types
         assert len(types) == 1
 
     def test_worker_properties(self):
@@ -187,7 +187,7 @@ class TestCondaWorkerBasic:
         """Test manifest compilation and validation."""
         # Test with dependencies field
         manifest1 = {
-            "type": "python-conda",
+            "type": "conda-jupyter-kernel",
             "dependencies": ["python=3.11", "numpy"],
             "channels": ["conda-forge"],
         }
@@ -203,7 +203,7 @@ class TestCondaWorkerBasic:
 
         # Test with dependencies field (alternate name)
         manifest2 = {
-            "type": "python-conda",
+            "type": "conda-jupyter-kernel",
             "dependencies": "python=3.11",  # String should be converted to list
             "channels": "conda-forge",  # String should be converted to list
         }
@@ -216,7 +216,7 @@ class TestCondaWorkerBasic:
         assert compiled_manifest["channels"] == ["conda-forge"]
 
         # Test with no dependencies (should add default)
-        manifest3 = {"type": "python-conda"}
+        manifest3 = {"type": "conda-jupyter-kernel"}
         compiled_manifest, files = await self.worker.compile(manifest3, [])
 
         deps = compiled_manifest["dependencies"]
@@ -234,10 +234,10 @@ class TestCondaWorkerBasic:
         assert "supported_types" in service_config
         assert "start" in service_config
         assert "stop" in service_config
-        assert "execute_code" in service_config
+        assert "execute" in service_config
 
         # Check supported types
-        assert "python-conda" in service_config["supported_types"]
+        assert "conda-jupyter-kernel" in service_config["supported_types"]
         assert len(service_config["supported_types"]) == 1
 
 
@@ -281,7 +281,7 @@ def execute(input_data):
             entry_point="main.py",
             artifact_id="test-artifact",
             manifest={
-                "type": "python-conda",
+                "type": "conda-jupyter-kernel",
                 "dependencies": ["python=3.11"],
                 "channels": ["conda-forge"],
                 "entry_point": "main.py",
@@ -322,24 +322,30 @@ result = {
 
 print(f"Result: {result}")
 """
-                result = await worker.execute_code(session_id, test_code)
+                result = await worker.execute(session_id, test_code)
 
                 assert (
-                    result.success
-                ), f"Execution failed: {result.error}\nStderr: {result.stderr}"
+                    result["status"] == "ok"
+                ), f"Execution failed: {result.get('error', {})}"
+
+                # Extract stdout from outputs
+                stdout_text = "".join(
+                    output.get("text", "") for output in result.get("outputs", [])
+                    if output.get("type") == "stream" and output.get("name") == "stdout"
+                )
 
                 # Check that the code executed successfully by looking at stdout
                 assert (
-                    "Result:" in result.stdout
-                ), f"Expected result output in stdout: {result.stdout}"
+                    "Result:" in stdout_text
+                ), f"Expected result output in stdout: {stdout_text}"
                 assert (
-                    "'computation': 42" in result.stdout
-                ), f"Expected computation=42 in stdout: {result.stdout}"
+                    "'computation': 42" in stdout_text
+                ), f"Expected computation=42 in stdout: {stdout_text}"
                 assert (
-                    "'input_data': 21" in result.stdout
-                ), f"Expected input_data=21 in stdout: {result.stdout}"
+                    "'input_data': 21" in stdout_text
+                ), f"Expected input_data=21 in stdout: {stdout_text}"
 
-                print(f"âœ… Execution successful: {result.stdout.strip()}")
+                print(f"âœ… Execution successful: {stdout_text.strip()}")
 
                 # Test another code execution
                 test_code2 = """
@@ -352,11 +358,18 @@ result = {
 
 print(f"Result2: {result}")
 """
-                result2 = await worker.execute_code(session_id, test_code2)
-                assert result2.success, f"Second execution failed: {result2.error}"
+                result2 = await worker.execute(session_id, test_code2)
+                assert result2["status"] == "ok", f"Second execution failed: {result2.get('error', {})}"
+                
+                # Extract stdout from outputs
+                stdout_text2 = "".join(
+                    output.get("text", "") for output in result2.get("outputs", [])
+                    if output.get("type") == "stream" and output.get("name") == "stdout"
+                )
+                
                 assert (
-                    "'computation': 45" in result2.stdout
-                ), f"Expected computation=45 in stdout: {result2.stdout}"
+                    "'computation': 45" in stdout_text2
+                ), f"Expected computation=45 in stdout: {stdout_text2}"
 
                 # Check logs
                 logs = await worker.get_logs(session_id)
@@ -425,7 +438,7 @@ def execute(input_data):
             entry_point="main.py",
             artifact_id="test-artifact",
             manifest={
-                "type": "python-conda",
+                "type": "conda-jupyter-kernel",
                 "dependencies": ["python=3.11", "numpy"],
                 "channels": ["conda-forge"],
                 "entry_point": "main.py",
@@ -467,22 +480,29 @@ result = {
 
 print(f"NumPy result: {result}")
 """
-                result = await worker.execute_code(session_id, test_code)
+                result = await worker.execute(session_id, test_code)
 
                 assert (
-                    result.success
-                ), f"Numpy test failed: {result.error}\nStderr: {result.stderr}"
+                    result["status"] == "ok"
+                ), f"Numpy test failed: {result.get('error', {})}"
+                
+                # Extract stdout from outputs
+                stdout_text = "".join(
+                    output.get("text", "") for output in result.get("outputs", [])
+                    if output.get("type") == "stream" and output.get("name") == "stdout"
+                )
+                
                 assert (
-                    "NumPy result:" in result.stdout
-                ), f"Expected result in stdout: {result.stdout}"
+                    "NumPy result:" in stdout_text
+                ), f"Expected result in stdout: {stdout_text}"
                 assert (
-                    "'array_sum': 15" in result.stdout
-                ), f"Expected array_sum=15 in stdout: {result.stdout}"
+                    "'array_sum': 15" in stdout_text
+                ), f"Expected array_sum=15 in stdout: {stdout_text}"
                 assert (
-                    "'input_sum': 150" in result.stdout
-                ), f"Expected input_sum=150 in stdout: {result.stdout}"
+                    "'input_sum': 150" in stdout_text
+                ), f"Expected input_sum=150 in stdout: {stdout_text}"
 
-                print(f"âœ… NumPy test successful: {result.stdout.strip()}")
+                print(f"âœ… NumPy test successful: {stdout_text.strip()}")
 
                 await worker.stop(session_id)
 
@@ -528,7 +548,7 @@ def execute(input_data):
             entry_point="main.py",
             artifact_id="test-artifact",
             manifest={
-                "type": "python-conda",
+                "type": "conda-jupyter-kernel",
                 "dependencies": ["python=3.11"],
                 "channels": ["conda-forge"],
                 "entry_point": "main.py",
@@ -563,8 +583,14 @@ result = {
 
 print(f"Cache test result 1: {result}")
 """
-                result1 = await worker.execute_code(session_id1, test_code1)
-                assert result1.success, f"First execution failed: {result1.error}"
+                result1 = await worker.execute(session_id1, test_code1)
+                assert result1["status"] == "ok", f"First execution failed: {result1.get('error', {})}"
+                
+                # Extract stdout from outputs
+                stdout_text1 = "".join(
+                    output.get("text", "") for output in result1.get("outputs", [])
+                    if output.get("type") == "stream" and output.get("name") == "stdout"
+                )
 
                 # Check cache was populated
                 first_cache_size = len(cache.index)
@@ -573,10 +599,10 @@ print(f"Cache test result 1: {result}")
                 # Extract environment path from stdout
                 import re
 
-                match1 = re.search(r"'python_executable': '([^']+)'", result1.stdout)
+                match1 = re.search(r"'python_executable': '([^']+)'", stdout_text1)
                 assert (
                     match1
-                ), f"Could not find python_executable in stdout: {result1.stdout}"
+                ), f"Could not find python_executable in stdout: {stdout_text1}"
                 env_path1 = match1.group(1)
 
                 await worker.stop(session_id1)
@@ -593,7 +619,7 @@ print(f"Cache test result 1: {result}")
                     entry_point="main.py",
                     artifact_id="test-artifact",
                     manifest={
-                        "type": "python-conda",
+                        "type": "conda-jupyter-kernel",
                         "dependencies": ["python=3.11"],  # Same dependencies
                         "channels": ["conda-forge"],  # Same channels
                         "entry_point": "main.py",
@@ -614,14 +640,20 @@ result = {
 
 print(f"Cache test result 2: {result}")
 """
-                result2 = await worker.execute_code(session_id2, test_code2)
-                assert result2.success, f"Second execution failed: {result2.error}"
+                result2 = await worker.execute(session_id2, test_code2)
+                assert result2["status"] == "ok", f"Second execution failed: {result2.get('error', {})}"
+                
+                # Extract stdout from outputs
+                stdout_text2 = "".join(
+                    output.get("text", "") for output in result2.get("outputs", [])
+                    if output.get("type") == "stream" and output.get("name") == "stdout"
+                )
 
                 # Extract environment path from stdout
-                match2 = re.search(r"'python_executable': '([^']+)'", result2.stdout)
+                match2 = re.search(r"'python_executable': '([^']+)'", stdout_text2)
                 assert (
                     match2
-                ), f"Could not find python_executable in stdout: {result2.stdout}"
+                ), f"Could not find python_executable in stdout: {stdout_text2}"
                 env_path2 = match2.group(1)
 
                 # Cache size should not have increased (reused existing)
@@ -698,7 +730,7 @@ def execute(input_data):
             entry_point="main.py",
             artifact_id="test-artifact",
             manifest={
-                "type": "python-conda",
+                "type": "conda-jupyter-kernel",
                 "dependencies": ["python=3.11", "numpy", {"pip": ["requests"]}],
                 "channels": ["conda-forge"],
                 "entry_point": "main.py",
@@ -747,40 +779,46 @@ result["data_processed"] = {
 
 print(f"Mixed dependencies result: {result}")
 """
-                result = await worker.execute_code(session_id, test_code)
+                result = await worker.execute(session_id, test_code)
 
                 assert (
-                    result.success
-                ), f"Mixed dependencies test failed: {result.error}\nStderr: {result.stderr}"
+                    result["status"] == "ok"
+                ), f"Mixed dependencies test failed: {result.get('error', {})}"
+                
+                # Extract stdout from outputs
+                stdout_text = "".join(
+                    output.get("text", "") for output in result.get("outputs", [])
+                    if output.get("type") == "stream" and output.get("name") == "stdout"
+                )
 
                 # Verify conda package (numpy) works
                 assert (
-                    "'numpy_available': True" in result.stdout
-                ), f"Expected numpy_available=True in stdout: {result.stdout}"
+                    "'numpy_available': True" in stdout_text
+                ), f"Expected numpy_available=True in stdout: {stdout_text}"
                 assert (
-                    "'numpy_version':" in result.stdout
-                ), f"Expected numpy_version in stdout: {result.stdout}"
+                    "'numpy_version':" in stdout_text
+                ), f"Expected numpy_version in stdout: {stdout_text}"
 
                 # Verify pip package (requests) works
                 assert (
-                    "'requests_available': True" in result.stdout
-                ), f"Expected requests_available=True in stdout: {result.stdout}"
+                    "'requests_available': True" in stdout_text
+                ), f"Expected requests_available=True in stdout: {stdout_text}"
                 assert (
-                    "'requests_version':" in result.stdout
-                ), f"Expected requests_version in stdout: {result.stdout}"
+                    "'requests_version':" in stdout_text
+                ), f"Expected requests_version in stdout: {stdout_text}"
 
                 # Verify data processing works - check for expected sum and mean
                 expected_sum = sum([1.5, 2.3, 3.7, 4.1, 5.9])  # 17.5
                 expected_mean = expected_sum / 5  # 3.5
                 assert (
-                    f"'sum': {expected_sum}" in result.stdout
-                ), f"Expected sum={expected_sum} in stdout: {result.stdout}"
+                    f"'sum': {expected_sum}" in stdout_text
+                ), f"Expected sum={expected_sum} in stdout: {stdout_text}"
                 assert (
-                    f"'mean': {expected_mean}" in result.stdout
-                ), f"Expected mean={expected_mean} in stdout: {result.stdout}"
+                    f"'mean': {expected_mean}" in stdout_text
+                ), f"Expected mean={expected_mean} in stdout: {stdout_text}"
 
                 print(f"âœ… Mixed dependencies test successful:")
-                print(f"  Output: {result.stdout.strip()}")
+                print(f"  Output: {stdout_text.strip()}")
 
                 await worker.stop(session_id)
 
@@ -835,7 +873,7 @@ print("=== Script completed successfully ===")
             entry_point="main.py",
             artifact_id="test-artifact",
             manifest={
-                "type": "python-conda",
+                "type": "conda-jupyter-kernel",
                 "dependencies": ["python=3.11"],
                 "channels": ["conda-forge"],
                 "entry_point": "main.py",
@@ -927,7 +965,7 @@ def execute(input_data):
             entry_point="main.py",
             artifact_id="test-artifact",
             manifest={
-                "type": "python-conda",
+                "type": "conda-jupyter-kernel",
                 "dependencies": ["python=3.11", "numpy"],
                 "channels": ["conda-forge"],
                 "entry_point": "main.py",
@@ -969,7 +1007,7 @@ def execute(input_data):
                 mock_result = MagicMock()
                 mock_result.success = True
                 mock_result.result = {"result": "test"}
-                mock_result.stdout = "Test output"
+                mock_stdout_text = "Test output"
                 mock_result.stderr = ""
                 mock_result.error = None
                 mock_result.timing = None
@@ -1042,7 +1080,7 @@ def execute(input_data):
             entry_point="main.py",
             artifact_id="test-artifact",
             manifest={
-                "type": "python-conda",
+                "type": "conda-jupyter-kernel",
                 "dependencies": ["python=3.11"],
                 "channels": ["conda-forge"],
                 "entry_point": "main.py",
@@ -1076,7 +1114,7 @@ def execute(input_data):
                 mock_result = MagicMock()
                 mock_result.success = True
                 mock_result.result = {"result": "cached_test"}
-                mock_result.stdout = "Cached test output"
+                mock_stdout_text = "Cached test output"
                 mock_result.stderr = ""
                 mock_result.error = None
                 mock_result.timing = None
@@ -1119,7 +1157,7 @@ def execute(input_data):
             entry_point="main.py",
             artifact_id="test-artifact",
             manifest={
-                "type": "python-conda",
+                "type": "conda-jupyter-kernel",
                 "dependencies": ["nonexistent-package==999.999.999"],
                 "channels": ["conda-forge"],
                 "entry_point": "main.py",
diff --git a/tests/test_conda_kernel.py b/tests/test_conda_kernel.py
new file mode 100644
index 0000000..82bb53d
--- /dev/null
+++ b/tests/test_conda_kernel.py
@@ -0,0 +1,407 @@
+"""Test Jupyter kernel functionality for conda worker."""
+
+import asyncio
+import os
+import tempfile
+import pytest
+import pytest_asyncio
+from pathlib import Path
+
+from hypha.workers.conda_kernel import CondaKernel
+from hypha.workers.conda import CondaWorker, get_available_package_manager
+
+
+@pytest_asyncio.fixture
+async def test_env_path():
+    """Create a test conda environment with ipykernel installed."""
+    # Use the active conda environment in CI
+    if os.environ.get("CI") == "true":
+        # In CI, we have a conda environment set up with setup-miniconda
+        # Get the environment path from the current Python executable
+        import sys
+        current_python = Path(sys.executable)
+        if current_python.name == "python":
+            # Python is in {env}/bin/python, so env path is parent of bin
+            env_path = current_python.parent.parent
+        else:  
+            # Fallback: assume it's in the bin directory
+            env_path = current_python.parent
+        yield env_path
+    else:
+        # For local testing, try to create a minimal conda env
+        try:
+            package_manager = get_available_package_manager()
+            with tempfile.TemporaryDirectory() as tmpdir:
+                env_path = Path(tmpdir) / "test_env"
+                
+                # Create minimal conda environment
+                cmd = [
+                    package_manager,
+                    "create",
+                    "-p", str(env_path),
+                    "-y",
+                    "-c", "conda-forge",
+                    "python=3.9",
+                    "ipykernel",
+                ]
+                
+                process = await asyncio.create_subprocess_exec(
+                    *cmd,
+                    stdout=asyncio.subprocess.PIPE,
+                    stderr=asyncio.subprocess.PIPE
+                )
+                
+                _, stderr = await process.communicate()
+                
+                if process.returncode != 0:
+                    pytest.skip(f"Failed to create test environment: {stderr.decode()}")
+                
+                yield env_path
+        except Exception:
+            pytest.skip("Conda not available for testing")
+
+
+@pytest.mark.asyncio
+async def test_conda_kernel_basic(test_env_path):
+    """Test basic kernel functionality."""
+    kernel = CondaKernel(test_env_path)
+    
+    try:
+        # Start the kernel
+        await kernel.start(timeout=30.0)
+        
+        # Check kernel is alive
+        assert await kernel.is_alive()
+        
+        # Execute simple code
+        result = await kernel.execute("print('Hello from kernel!')")
+        
+        assert result["status"] == "ok"
+        assert len(result["outputs"]) > 0
+        
+        # Find stdout output
+        stdout_found = False
+        for output in result["outputs"]:
+            if output["type"] == "stream" and output["name"] == "stdout":
+                assert "Hello from kernel!" in output["text"]
+                stdout_found = True
+                break
+        
+        assert stdout_found, "Expected stdout output not found"
+        
+    finally:
+        # Cleanup
+        await kernel.shutdown()
+
+
+@pytest.mark.asyncio
+async def test_conda_kernel_execute_with_result(test_env_path):
+    """Test kernel execution with results."""
+    kernel = CondaKernel(test_env_path)
+    
+    try:
+        await kernel.start(timeout=30.0)
+        
+        # Execute code that returns a value
+        result = await kernel.execute("2 + 3")
+        
+        assert result["status"] == "ok"
+        
+        # Check for execute_result
+        execute_result_found = False
+        for output in result["outputs"]:
+            if output["type"] == "execute_result":
+                assert "5" in output["data"]["text/plain"]
+                execute_result_found = True
+                break
+        
+        assert execute_result_found, "Expected execute_result not found"
+        
+    finally:
+        await kernel.shutdown()
+
+
+@pytest.mark.asyncio
+async def test_conda_kernel_error_handling(test_env_path):
+    """Test kernel error handling."""
+    kernel = CondaKernel(test_env_path)
+    
+    try:
+        await kernel.start(timeout=30.0)
+        
+        # Execute code with error
+        result = await kernel.execute("1 / 0")
+        
+        assert result["status"] == "error"
+        assert result["error"] is not None
+        assert result["error"]["ename"] == "ZeroDivisionError"
+        
+        # Check error in outputs
+        error_found = False
+        for output in result["outputs"]:
+            if output["type"] == "error":
+                assert output["ename"] == "ZeroDivisionError"
+                error_found = True
+                break
+        
+        assert error_found, "Expected error output not found"
+        
+    finally:
+        await kernel.shutdown()
+
+
+@pytest.mark.asyncio
+async def test_conda_kernel_interrupt(test_env_path):
+    """Test kernel interrupt functionality."""
+    kernel = CondaKernel(test_env_path)
+    
+    try:
+        await kernel.start(timeout=30.0)
+        
+        # Start long-running code
+        async def execute_long_running():
+            return await kernel.execute("""
+import time
+for i in range(10):
+    print(f"Iteration {i}")
+    time.sleep(1)
+""")
+        
+        # Start execution
+        task = asyncio.create_task(execute_long_running())
+        
+        # Wait a bit then interrupt
+        await asyncio.sleep(2)
+        await kernel.interrupt()
+        
+        # Wait for task to complete
+        try:
+            result = await asyncio.wait_for(task, timeout=5)
+            # Execution was interrupted
+            assert result["status"] == "error" or len(result["outputs"]) < 10
+        except asyncio.TimeoutError:
+            # This is also acceptable - execution was stopped
+            pass
+        
+    finally:
+        await kernel.shutdown()
+
+
+@pytest.mark.asyncio
+async def test_conda_kernel_restart(test_env_path):
+    """Test kernel restart functionality."""
+    kernel = CondaKernel(test_env_path)
+    
+    try:
+        await kernel.start(timeout=30.0)
+        
+        # Set a variable
+        result1 = await kernel.execute("test_var = 42")
+        assert result1["status"] == "ok"
+        
+        # Verify variable exists
+        result2 = await kernel.execute("print(test_var)")
+        assert result2["status"] == "ok"
+        
+        # Restart kernel
+        await kernel.restart()
+        
+        # Variable should not exist after restart
+        result3 = await kernel.execute("print(test_var)")
+        assert result3["status"] == "error"
+        assert result3["error"]["ename"] == "NameError"
+        
+    finally:
+        await kernel.shutdown()
+
+
+@pytest.mark.asyncio
+async def test_conda_worker_execute_api():
+    """Test the new execute API in CondaWorker."""
+    worker = CondaWorker()
+    
+    # Create a test config
+    config = {
+        "id": "test-workspace/test-client",
+        "app_id": "test-app",
+        "workspace": "test-workspace",
+        "client_id": "test-client",
+        "server_url": "http://localhost:9527",
+        "token": "test-token",
+        "entry_point": "main.py",
+        "artifact_id": "test-workspace/test-app",
+        "manifest": {
+            "name": "Test App",
+            "type": "conda-jupyter-kernel",
+            "dependencies": ["python=3.9", "numpy"],
+            "channels": ["conda-forge"]
+        },
+        "app_files_base_url": "http://localhost:9527/test"
+    }
+    
+    # Mock the script fetching
+    async def mock_get(url, headers=None):
+        class MockResponse:
+            def raise_for_status(self):
+                pass
+            @property
+            def text(self):
+                return "print('Initialization script executed')"
+        return MockResponse()
+    
+    # Patch httpx client
+    import hypha.workers.conda
+    original_client = hypha.workers.conda.httpx.AsyncClient
+    
+    class MockAsyncClient:
+        async def __aenter__(self):
+            return self
+        async def __aexit__(self, *args):
+            pass
+        async def get(self, *args, **kwargs):
+            return await mock_get(*args, **kwargs)
+    
+    try:
+        hypha.workers.conda.httpx.AsyncClient = MockAsyncClient
+        
+        # Start session
+        session_id = await worker.start(config)
+        
+        # Wait for kernel to be ready
+        await asyncio.sleep(2)
+        
+        # Test execute method
+        result = await worker.execute(
+            session_id=session_id,
+            script="print('Hello from execute API!')",
+            config={"timeout": 10.0}
+        )
+        
+        assert result["status"] == "ok"
+        assert any(
+            "Hello from execute API!" in output.get("text", "")
+            for output in result["outputs"]
+            if output["type"] == "stream"
+        )
+        
+        # Test with calculation
+        result2 = await worker.execute(
+            session_id=session_id,
+            script="result = 10 * 5\nprint(f'Result: {result}')",
+            config={"timeout": 10.0}
+        )
+        
+        assert result2["status"] == "ok"
+        assert any(
+            "Result: 50" in output.get("text", "")
+            for output in result2["outputs"]
+            if output["type"] == "stream"
+        )
+        
+        # Test error handling
+        result3 = await worker.execute(
+            session_id=session_id,
+            script="raise ValueError('Test error')",
+            config={"timeout": 10.0}
+        )
+        
+        assert result3["status"] == "error"
+        assert result3["error"]["ename"] == "ValueError"
+        assert "Test error" in result3["error"]["evalue"]
+        
+        # Test with progress callback
+        progress_messages = []
+        def progress_callback(msg):
+            progress_messages.append(msg)
+        
+        result4 = await worker.execute(
+            session_id=session_id,
+            script="print('Progress callback test')",
+            config={"timeout": 10.0},
+            progress_callback=progress_callback
+        )
+        
+        assert result4["status"] == "ok"
+        
+    finally:
+        # Restore original client
+        hypha.workers.conda.httpx.AsyncClient = original_client
+        
+        # Cleanup
+        await worker.stop(session_id)
+
+
+@pytest.mark.asyncio
+async def test_conda_worker_session_persistence():
+    """Test that variables persist across execute calls."""
+    worker = CondaWorker()
+    
+    config = {
+        "id": "test-workspace/test-client-2",
+        "app_id": "test-app-2",
+        "workspace": "test-workspace",
+        "client_id": "test-client-2",
+        "server_url": "http://localhost:9527",
+        "token": "test-token",
+        "entry_point": "main.py",
+        "artifact_id": "test-workspace/test-app-2",
+        "manifest": {
+            "name": "Test App 2",
+            "type": "conda-jupyter-kernel",
+            "dependencies": ["python=3.9"],
+            "channels": ["conda-forge"]
+        },
+        "app_files_base_url": "http://localhost:9527/test"
+    }
+    
+    # Mock httpx as before
+    import hypha.workers.conda
+    original_client = hypha.workers.conda.httpx.AsyncClient
+    
+    class MockAsyncClient:
+        async def __aenter__(self):
+            return self
+        async def __aexit__(self, *args):
+            pass
+        async def get(self, *args, **kwargs):
+            class MockResponse:
+                def raise_for_status(self):
+                    pass
+                @property
+                def text(self):
+                    return "# Initialization"
+            return MockResponse()
+    
+    try:
+        hypha.workers.conda.httpx.AsyncClient = MockAsyncClient
+        
+        session_id = await worker.start(config)
+        await asyncio.sleep(2)
+        
+        # Set a variable
+        result1 = await worker.execute(
+            session_id=session_id,
+            script="my_data = [1, 2, 3, 4, 5]\nprint('Data set')"
+        )
+        assert result1["status"] == "ok"
+        
+        # Use the variable in another call
+        result2 = await worker.execute(
+            session_id=session_id,
+            script="import numpy as np\nprint(f'Mean: {np.mean(my_data)}')"
+        )
+        assert result2["status"] == "ok"
+        assert any(
+            "Mean: 3.0" in output.get("text", "")
+            for output in result2["outputs"]
+            if output["type"] == "stream"
+        )
+        
+    finally:
+        hypha.workers.conda.httpx.AsyncClient = original_client
+        await worker.stop(session_id)
+
+
+if __name__ == "__main__":
+    # Run tests
+    pytest.main([__file__, "-v"])
\ No newline at end of file
diff --git a/tests/test_server_apps.py b/tests/test_server_apps.py
index 8bc5ff5..f5f0b48 100644
--- a/tests/test_server_apps.py
+++ b/tests/test_server_apps.py
@@ -1302,7 +1302,7 @@ async def test_service_selection_mode_with_multiple_instances(
     try:
         response = requests.post(
             service_url,
-            json="HTTP service test",
+            json=["HTTP service test"],
             headers={"Authorization": f"Bearer {test_user_token}"},
         )
 
@@ -1754,8 +1754,8 @@ print("This won't be reached")
     await api.disconnect()
 
 
-# Test Python code for the python-conda app type
-TEST_CONDA_PYTHON_CODE = """
+# Test Python code for the conda-jupyter-kernel app type
+TEST_CONDA_JUPYTER_KERNEL = """
 import sys
 import numpy as np
 
@@ -1784,14 +1784,14 @@ def execute(input_data=None):
     \"\"\"Simple execute function for interactive calls.\"\"\"
     if input_data is None:
         return {
-            "message": "Hello from python-conda app!",
+            "message": "Hello from conda-jupyter-kernel app!",
             "numpy_version": np.__version__,
             "python_version": f"{sys.version_info.major}.{sys.version_info.minor}",
         }
     return {"input": input_data, "processed": True}
 """
 
-# Test Python code for conda-python app with FastAPI service registration
+# Test Python code for conda-jupyter-kernel app with FastAPI service registration
 TEST_CONDA_FASTAPI_CODE = """
 import sys
 import os
@@ -1899,8 +1899,8 @@ while True:
 """
 
 
-async def test_conda_python_apps(fastapi_server, test_user_token, conda_available):
-    """Test python-conda app installation and execution."""
+async def test_conda_jupyter_kernel_apps(fastapi_server, test_user_token, conda_available):
+    """Test conda-jupyter-kernel app installation and execution."""
     api = await connect_to_server(
         {
             "name": "test client",
@@ -1912,8 +1912,8 @@ async def test_conda_python_apps(fastapi_server, test_user_token, conda_availabl
 
     controller = await api.get_service("public/server-apps")
 
-    # Test 1: Basic python-conda app (original test)
-    print("=== Test 1: Basic conda-python app with NumPy ===")
+    # Test 1: Basic conda-jupyter-kernel app (original test)
+    print("=== Test 1: Basic conda-jupyter-kernel app with NumPy ===")
 
     # Create progress callback to capture conda environment setup progress
     progress_messages = []
@@ -1924,13 +1924,13 @@ async def test_conda_python_apps(fastapi_server, test_user_token, conda_availabl
         print(f"ðŸ“Š Progress: {message['message']}")
 
     app_info = await controller.install(
-        source=TEST_CONDA_PYTHON_CODE,
+        source=TEST_CONDA_JUPYTER_KERNEL,
         manifest={
             "name": "Test Conda Python App",
-            "type": "python-conda",
+            "type": "conda-jupyter-kernel",
             "version": "1.0.0",
             "entry_point": "main.py",
-            "description": "A test python-conda app with numpy",
+            "description": "A test conda-jupyter-kernel app with numpy",
             "dependencies": ["python=3.11", "numpy"],
             "channels": ["conda-forge"],
         },
@@ -1941,7 +1941,7 @@ async def test_conda_python_apps(fastapi_server, test_user_token, conda_availabl
     )
 
     assert app_info["name"] == "Test Conda Python App"
-    assert app_info["type"] == "python-conda"
+    assert app_info["type"] == "conda-jupyter-kernel"
     assert app_info["entry_point"] == "main.py"
 
     # Verify that progress messages were captured during conda environment setup
@@ -1965,7 +1965,7 @@ async def test_conda_python_apps(fastapi_server, test_user_token, conda_availabl
 
     print("âœ… Conda environment setup progress captured successfully!")
 
-    # Test starting the python-conda app (without waiting for service)
+    # Test starting the conda-jupyter-kernel app (without waiting for service)
     started_app = await controller.start(
         app_info["id"],
         timeout=90,
@@ -2005,10 +2005,10 @@ async def test_conda_python_apps(fastapi_server, test_user_token, conda_availabl
     await controller.stop(started_app["id"])
     await controller.uninstall(app_info["id"])
 
-    print("âœ… Basic conda-python app test completed")
+    print("âœ… Basic conda-jupyter-kernel app test completed")
 
-    # Test 2: FastAPI service registration with conda-python (enhanced test)
-    print("=== Test 2: Conda-python app with FastAPI service registration ===")
+    # Test 2: FastAPI service registration with conda-jupyter-kernel (enhanced test)
+    print("=== Test 2: conda-jupyter-kernel app with FastAPI service registration ===")
 
     # Create progress callback for FastAPI app installation
     fastapi_progress_messages = []
@@ -2022,10 +2022,10 @@ async def test_conda_python_apps(fastapi_server, test_user_token, conda_availabl
         source=TEST_CONDA_FASTAPI_CODE,
         manifest={
             "name": "Test Conda FastAPI App",
-            "type": "python-conda",
+            "type": "conda-jupyter-kernel",
             "version": "1.0.0",
             "entry_point": "main.py",
-            "description": "A conda-python FastAPI app with service registration",
+            "description": "A conda-jupyter-kernel FastAPI app with service registration",
             "dependencies": [
                 "python=3.11",
                 "numpy",
@@ -2048,7 +2048,7 @@ async def test_conda_python_apps(fastapi_server, test_user_token, conda_availabl
     )
 
     assert fastapi_app_info["name"] == "Test Conda FastAPI App"
-    assert fastapi_app_info["type"] == "python-conda"
+    assert fastapi_app_info["type"] == "conda-jupyter-kernel"
     print(f"âœ… FastAPI conda app installed: {fastapi_app_info['id']}")
 
     # Verify FastAPI app progress messages
@@ -2195,7 +2195,7 @@ print("This won't be reached")
             source=error_python_code,
             manifest={
                 "name": "Test Conda Python App Error",
-                "type": "python-conda",
+                "type": "conda-jupyter-kernel",
                 "version": "1.0.0",
                 "entry_point": "error.py",
                 "dependencies": ["python=3.11"],
@@ -2206,7 +2206,7 @@ print("This won't be reached")
         )
 
     print("âœ… Error handling test completed")
-    print("ðŸŽ‰ All conda-python app tests completed successfully!")
+    print("ðŸŽ‰ All conda-jupyter-kernel app tests completed successfully!")
 
     await api.disconnect()
 
diff --git a/tests/test_worker.py b/tests/test_worker.py
index 1f4b11a..f7ac089 100644
--- a/tests/test_worker.py
+++ b/tests/test_worker.py
@@ -134,14 +134,14 @@ async def test_conda_worker_service_registration(fastapi_server, test_user_token
     assert worker_service is not None
     assert hasattr(worker_service, "start")
     assert hasattr(worker_service, "stop")
-    assert hasattr(worker_service, "execute_code")
+    assert hasattr(worker_service, "execute")
     assert hasattr(worker_service, "get_logs")
     assert hasattr(worker_service, "list_sessions")
 
     print("âœ“ Conda worker registered successfully")
 
     # Test supported types
-    assert "python-conda" in worker.supported_types
+    assert "conda-jupyter-kernel" in worker.supported_types
     print(f"âœ“ Conda worker supports types: {worker.supported_types}")
 
     # Test worker info
@@ -253,7 +253,7 @@ async def test_conda_worker_session_lifecycle(fastapi_server, test_user_token):
         "entry_point": "main.py",
         "artifact_id": f"{workspace}/test-conda-app",
         "manifest": {
-            "type": "python-conda",
+            "type": "conda-jupyter-kernel",
             "name": "Test Conda App",
             "entry_point": "main.py",
             "dependencies": ["python=3.11", "numpy"],
